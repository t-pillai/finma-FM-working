{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINMA Python Lab 08: NumPy, Pandas and Matplotlib for Financial Analysis\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this lab, you'll practice:\n",
    "- NumPy arrays and operations\n",
    "- Financial calculations with NumPy\n",
    "- Pandas DataFrames for tabular data\n",
    "- Reading and writing data with Pandas\n",
    "- Data manipulation and aggregation\n",
    "- Time series analysis\n",
    "- Calculating financial metrics\n",
    "- Portfolio analysis\n",
    "\n",
    "**Important:** Complete your work and have it manually checked by your instructor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Programming Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Portfolio Value Calculation (NumPy)\n",
    "\n",
    "Using NumPy arrays:\n",
    "1. Create arrays for: symbols, shares, and prices\n",
    "2. Calculate the value of each position\n",
    "3. Calculate the total portfolio value\n",
    "4. Calculate the percentage allocation for each position\n",
    "\n",
    "**Data:**\n",
    "- AAPL: 150 shares at $163.75\n",
    "- GOOGL: 75 shares at $155.30\n",
    "- MSFT: 100 shares at $406.20\n",
    "- AMZN: 60 shares at $200.45\n",
    "- TSLA: 40 shares at $276.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Portfolio Value Calculation\n",
    "# Write your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Return Statistics (NumPy)\n",
    "\n",
    "Given daily returns for a stock, calculate:\n",
    "1. Average daily return\n",
    "2. Volatility (standard deviation)\n",
    "3. Annualized return (assume 252 trading days)\n",
    "4. Annualized volatility\n",
    "5. Sharpe ratio (assume risk-free rate = 2%)\n",
    "\n",
    "**Formula:** Sharpe Ratio = (Annualized Return - Risk Free Rate) / Annualized Volatility\n",
    "\n",
    "**Data:** Use returns array: `[1.2, -0.5, 0.8, 1.5, -0.3, 0.9, 1.1, -0.7, 1.3, 0.6]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Return Statistics\n",
    "# Write your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Price Matrix Analysis (NumPy)\n",
    "\n",
    "Create a 2D NumPy array representing 10 days of prices for 5 stocks.\n",
    "\n",
    "Calculate:\n",
    "1. Average price for each stock (across all days)\n",
    "2. Highest price for each stock\n",
    "3. Lowest price for each stock\n",
    "4. Which stock had the highest average price?\n",
    "5. Which day had the highest average price across all stocks?\n",
    "\n",
    "**Use the first 10 days from stock_prices_timeseries.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Price Matrix Analysis\n",
    "# Write your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: DataFrame Creation and Analysis (Pandas)\n",
    "\n",
    "Create a DataFrame from the company_info.csv file and:\n",
    "1. Display the first 5 rows\n",
    "2. Show summary statistics\n",
    "3. Find the company with the highest market cap\n",
    "4. Find the company with the highest P/E ratio\n",
    "5. Calculate the average dividend yield by sector\n",
    "6. List all Technology sector companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comany with highest market cap:\n",
      "AAPL\n",
      "\n",
      "Comany with highest market cap:\n",
      "Tesla Inc.\n",
      "\n",
      "Technology average dividend yield: 0.19%\n",
      "Financials average dividend yield: 2.53%\n",
      "Healthcare average dividend yield: 2.37%\n",
      "Energy average dividend yield: 3.63%\n",
      "Consumer Staples average dividend yield: 2.33%\n",
      "Consumer Discretionary average dividend yield: 2.50%\n",
      "\n",
      "Technology companies are:\n",
      " 0               Apple Inc.\n",
      "1    Microsoft Corporation\n",
      "2            Alphabet Inc.\n",
      "3          Amazon.com Inc.\n",
      "4               Tesla Inc.\n",
      "5      Meta Platforms Inc.\n",
      "6       NVIDIA Corporation\n",
      "Name: company, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: DataFrame Creation and Analysis\n",
    "# Write your code here\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"company_info.csv\")\n",
    "\n",
    "#print(df)\n",
    "\n",
    "#print(df.head())\n",
    "#print(df.describe())\n",
    "\n",
    "#using sort method\n",
    "sorted_df1 = df.sort_values(by='market_cap', ascending = False)\n",
    "print(\"Comany with highest market cap:\")\n",
    "print(sorted_df1.iloc[0,0])\n",
    "print()\n",
    "\n",
    "#using idmax method\n",
    "sorted_df2 = df['pe_ratio'].idxmax()\n",
    "print(f\"Comany with highest market cap:\")\n",
    "print(df.loc[sorted_df2, 'company'])\n",
    "print()\n",
    "\n",
    "\n",
    "tech_avg = df.loc[df['sector'] == \"Technology\", 'dividend_yield'].mean()\n",
    "fin_avg  = df.loc[df['sector'] == \"Financials\", 'dividend_yield'].mean()\n",
    "hc_avg   = df.loc[df['sector'] == \"Healthcare\", 'dividend_yield'].mean()\n",
    "en_avg   = df.loc[df['sector'] == \"Energy\", 'dividend_yield'].mean()\n",
    "cs_avg   = df.loc[df['sector'] == \"Consumer Staples\", 'dividend_yield'].mean()\n",
    "cd_avg   = df.loc[df['sector'] == \"Consumer Discretionary\", 'dividend_yield'].mean()\n",
    "\n",
    "print(f\"Technology average dividend yield: {tech_avg:.2f}%\")\n",
    "print(f\"Financials average dividend yield: {fin_avg:.2f}%\")\n",
    "print(f\"Healthcare average dividend yield: {hc_avg:.2f}%\")\n",
    "print(f\"Energy average dividend yield: {en_avg:.2f}%\")\n",
    "print(f\"Consumer Staples average dividend yield: {cs_avg:.2f}%\")\n",
    "print(f\"Consumer Discretionary average dividend yield: {cd_avg:.2f}%\")\n",
    "print()\n",
    "\n",
    "tech_comp = df.loc[df['sector'] == \"Technology\"]\n",
    "print(f\"Technology companies are:\\n {tech_comp['company']}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Transaction Analysis (Pandas)\n",
    "\n",
    "Read transactions.csv and:\n",
    "1. Calculate total shares bought and sold for each symbol\n",
    "2. Calculate total commission paid\n",
    "3. Calculate average buy price and average sell price for each symbol\n",
    "4. Determine current holdings (shares bought - shares sold)\n",
    "5. Export a summary to CSV with columns: symbol, shares_held, avg_buy_price, total_commission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of shares is: 19022.9\n",
      "The total commission paid is: 298.50\n",
      "\n",
      " Average Prices: \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SeriesGroupBy' object has no attribute 'mean:'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe total commission paid is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msum_commission\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m Average Prices: \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m avg_prices = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msymbol\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43maction\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mprice\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmean:\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mshares\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msum\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     18\u001b[39m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(avg_prices)\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m Current Holdings: \u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pandas/core/groupby/generic.py:1432\u001b[39m, in \u001b[36mDataFrameGroupBy.aggregate\u001b[39m\u001b[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m   1429\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine_kwargs\u001b[39m\u001b[33m\"\u001b[39m] = engine_kwargs\n\u001b[32m   1431\u001b[39m op = GroupByApply(\u001b[38;5;28mself\u001b[39m, func, args=args, kwargs=kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1432\u001b[39m result = \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1433\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dict_like(func) \u001b[38;5;129;01mand\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1434\u001b[39m     \u001b[38;5;66;03m# GH #52849\u001b[39;00m\n\u001b[32m   1435\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.as_index \u001b[38;5;129;01mand\u001b[39;00m is_list_like(func):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pandas/core/apply.py:190\u001b[39m, in \u001b[36mApply.agg\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_str()\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(func):\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magg_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(func):\n\u001b[32m    192\u001b[39m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[32m    193\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.agg_list_like()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pandas/core/apply.py:423\u001b[39m, in \u001b[36mApply.agg_dict_like\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34magg_dict_like\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> DataFrame | Series:\n\u001b[32m    416\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    417\u001b[39m \u001b[33;03m    Compute aggregation in the case of a dict-like argument.\u001b[39;00m\n\u001b[32m    418\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    421\u001b[39m \u001b[33;03m    Result of aggregation.\u001b[39;00m\n\u001b[32m    422\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magg_or_apply_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43magg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pandas/core/apply.py:1603\u001b[39m, in \u001b[36mGroupByApply.agg_or_apply_dict_like\u001b[39m\u001b[34m(self, op_name)\u001b[39m\n\u001b[32m   1598\u001b[39m     kwargs.update({\u001b[33m\"\u001b[39m\u001b[33mengine\u001b[39m\u001b[33m\"\u001b[39m: engine, \u001b[33m\"\u001b[39m\u001b[33mengine_kwargs\u001b[39m\u001b[33m\"\u001b[39m: engine_kwargs})\n\u001b[32m   1600\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m com.temp_setattr(\n\u001b[32m   1601\u001b[39m     obj, \u001b[33m\"\u001b[39m\u001b[33mas_index\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, condition=\u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[33m\"\u001b[39m\u001b[33mas_index\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1602\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1603\u001b[39m     result_index, result_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_dict_like\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1604\u001b[39m \u001b[43m        \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1605\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1606\u001b[39m result = \u001b[38;5;28mself\u001b[39m.wrap_results_dict_like(selected_obj, result_index, result_data)\n\u001b[32m   1607\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pandas/core/apply.py:497\u001b[39m, in \u001b[36mApply.compute_dict_like\u001b[39m\u001b[34m(self, op_name, selected_obj, selection, kwargs)\u001b[39m\n\u001b[32m    493\u001b[39m         results += key_data\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    495\u001b[39m     \u001b[38;5;66;03m# key used for column selection and output\u001b[39;00m\n\u001b[32m    496\u001b[39m     results = [\n\u001b[32m--> \u001b[39m\u001b[32m497\u001b[39m         \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gotitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    498\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m key, how \u001b[38;5;129;01min\u001b[39;00m func.items()\n\u001b[32m    499\u001b[39m     ]\n\u001b[32m    500\u001b[39m     keys = \u001b[38;5;28mlist\u001b[39m(func.keys())\n\u001b[32m    502\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m keys, results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pandas/core/groupby/generic.py:249\u001b[39m, in \u001b[36mSeriesGroupBy.aggregate\u001b[39m\u001b[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m    247\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m engine_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    248\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine_kwargs\u001b[39m\u001b[33m\"\u001b[39m] = engine_kwargs\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m(*args, **kwargs)\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, abc.Iterable):\n\u001b[32m    252\u001b[39m     \u001b[38;5;66;03m# Catch instances of lists / tuples\u001b[39;00m\n\u001b[32m    253\u001b[39m     \u001b[38;5;66;03m# but not the class list / tuple itself.\u001b[39;00m\n\u001b[32m    254\u001b[39m     func = maybe_mangle_lambdas(func)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1365\u001b[39m, in \u001b[36mGroupBy.__getattr__\u001b[39m\u001b[34m(self, attr)\u001b[39m\n\u001b[32m   1362\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj:\n\u001b[32m   1363\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[attr]\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1366\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1367\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'SeriesGroupBy' object has no attribute 'mean:'"
     ]
    }
   ],
   "source": [
    "# Exercise 5: Transaction Analysis\n",
    "# Write your code here\n",
    "\n",
    "df = pd.read_csv(\"transactions.csv\")\n",
    "\n",
    "#print(df)\n",
    "\n",
    "sum_shares = df[\"price\"].sum()\n",
    "print(f\"The total number of shares is: {sum_shares}\")\n",
    "\n",
    "sum_commission = df[\"commission\"].sum()\n",
    "print(f\"The total commission paid is: {sum_commission:.2f}\")\n",
    "\n",
    "print(\"\\n Average Prices: \")\n",
    "avg_prices = df.groupby(['symbol', 'action']).agg({\n",
    "    'price': 'mean:', \n",
    "    'shares': 'sum'\n",
    "})\n",
    "print(avg_prices)\n",
    "\n",
    "print(\"\\n Current Holdings: \")\n",
    "buys = pd[pd['action'] == 'BUY'].groupby('symbol')['shares'].sum()\n",
    "sells = pd[pd['action'] == 'SELL'].groupby('symbol')['shares'].sum()\n",
    "print(buys)\n",
    "print(sells)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6: Time Series Returns (Pandas)\n",
    "\n",
    "Using stock_prices_timeseries.csv:\n",
    "1. Read the data with Date as index\n",
    "2. Calculate daily returns for all stocks\n",
    "3. Calculate cumulative returns for all stocks\n",
    "4. Find which stock had:\n",
    "   - Highest total return\n",
    "   - Lowest total return\n",
    "   - Highest volatility (std of daily returns)\n",
    "   - Lowest volatility\n",
    "5. Export the daily returns to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 6: Time Series Returns\n",
    "# Write your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7: Moving Averages (Pandas)\n",
    "\n",
    "Using stock_prices_timeseries.csv:\n",
    "1. Calculate 5-day and 10-day moving averages for AAPL\n",
    "2. Identify days where price crosses above the 5-day MA (potential buy signal)\n",
    "3. Identify days where price crosses below the 5-day MA (potential sell signal)\n",
    "4. Calculate how many buy and sell signals occurred\n",
    "5. Create a new DataFrame with columns: Date, Price, MA5, MA10, Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 7: Moving Averages\n",
    "# Write your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8: Portfolio Performance Report (Combined)\n",
    "\n",
    "Create a comprehensive portfolio performance report:\n",
    "\n",
    "1. Read transactions.csv to determine current holdings\n",
    "2. Read stock_prices_timeseries.csv to get latest prices\n",
    "3. Merge company_info.csv to get sector information\n",
    "4. Calculate for each holding:\n",
    "   - Current value\n",
    "   - Cost basis\n",
    "   - Unrealized gain/loss\n",
    "   - Return percentage\n",
    "5. Calculate portfolio-level metrics:\n",
    "   - Total value\n",
    "   - Total cost\n",
    "   - Total gain/loss\n",
    "   - Overall return %\n",
    "   - Allocation by sector\n",
    "6. Export to CSV with all details\n",
    "\n",
    "**Hint:** Use the last price in the time series as the current price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 8: Portfolio Performance Report\n",
    "# Write your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9: Correlation Analysis (Pandas + NumPy)\n",
    "\n",
    "Analyze correlations between stocks:\n",
    "1. Read stock_prices_timeseries.csv\n",
    "2. Calculate daily returns for all stocks\n",
    "3. Create a correlation matrix of returns\n",
    "4. Find the pair of stocks with:\n",
    "   - Highest correlation\n",
    "   - Lowest correlation\n",
    "5. Calculate portfolio variance for an equal-weighted portfolio\n",
    "\n",
    "**Hint:** Use `df.corr()` for correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 9: Correlation Analysis\n",
    "# Write your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10: Risk-Adjusted Returns (Advanced)\n",
    "\n",
    "Calculate risk-adjusted metrics for each stock:\n",
    "1. Calculate daily returns and annualized returns (252 trading days)\n",
    "2. Calculate volatility (std) and annualized volatility\n",
    "3. Calculate Sharpe Ratio (risk-free rate = 2%)\n",
    "4. Calculate Maximum Drawdown for each stock\n",
    "5. Create a summary DataFrame ranking stocks by:\n",
    "   - Total return\n",
    "   - Sharpe ratio\n",
    "   - Risk (volatility)\n",
    "6. Export the analysis to CSV\n",
    "\n",
    "**Formula for Maximum Drawdown:**\n",
    "```\n",
    "Running maximum = cumulative maximum of prices\n",
    "Drawdown = (Current price - Running maximum) / Running maximum\n",
    "Maximum Drawdown = minimum drawdown value\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 10: Risk-Adjusted Returns\n",
    "# Write your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11: Plot Return Distribution (Matplotlib)\n",
    "\n",
    "Plot a histogram of provided daily returns:\n",
    "1. Use the returns array below.\n",
    "2. Plot a histogram with 20â€“30 bins, add a vertical line at the mean, and show grid/labels/title.\n",
    "3. Annotate the chart with mean and standard deviation.\n",
    "4. Optionally save as `returns_histogram.png`.\n",
    "\n",
    "**Data:**\n",
    "- `returns = [0.004, -0.003, 0.006, 0.002, 0.005, -0.001, 0.007, 0.003, -0.002, 0.004, 0.006, 0.001, 0.005, -0.002, 0.003, 0.004, 0.002, 0.005, 0.006, 0.003]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 11: Plot Return Distribution\n",
    "# Write your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12: Plot Hypothetical Share Prices (Matplotlib)\n",
    "\n",
    "Plot provided price paths for two stocks:\n",
    "1. Use the given dates and prices.\n",
    "2. Plot both series on one line chart with title, axes labels, legend, and grid.\n",
    "3. Optionally save as `hypothetical_prices.png`.\n",
    "\n",
    "**Data:**\n",
    "- `dates = [\"2024-01-02\", \"2024-01-03\", \"2024-01-04\", \"2024-01-05\", \"2024-01-08\", \"2024-01-09\", \"2024-01-10\", \"2024-01-11\", \"2024-01-12\", \"2024-01-15\"]`\n",
    "- `aapl = [150.0, 151.5, 150.8, 152.3, 153.0, 154.2, 153.7, 155.0, 154.5, 156.0]`\n",
    "- `msft = [320.0, 321.0, 322.5, 321.8, 323.0, 324.5, 325.0, 324.0, 326.5, 327.0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 12: Plot Hypothetical Share Prices\n",
    "# Write your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: Key Concepts\n",
    "\n",
    "### NumPy:\n",
    "```python\n",
    "# Array creation\n",
    "arr = np.array([1, 2, 3])\n",
    "zeros = np.zeros(5)\n",
    "ones = np.ones((3, 4))  # 3x4 matrix\n",
    "range_arr = np.arange(0, 10, 2)\n",
    "\n",
    "# Operations (vectorized)\n",
    "arr * 2              # Multiply all elements\n",
    "arr1 + arr2          # Element-wise addition\n",
    "np.mean(arr)         # Average\n",
    "np.std(arr)          # Standard deviation\n",
    "np.sum(arr)          # Sum\n",
    "\n",
    "# 2D operations\n",
    "matrix.mean(axis=0)  # Mean of each column\n",
    "matrix.mean(axis=1)  # Mean of each row\n",
    "```\n",
    "\n",
    "### Pandas:\n",
    "```python\n",
    "# Reading data\n",
    "df = pd.read_csv('file.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Selection\n",
    "df['column']                # Single column (Series)\n",
    "df[['col1', 'col2']]        # Multiple columns\n",
    "df[df['price'] > 100]       # Filter rows\n",
    "df.iloc[0]                  # By position\n",
    "df.loc['2025-12-01']        # By label\n",
    "\n",
    "# Operations\n",
    "df['new'] = df['a'] * df['b']  # New column\n",
    "df.pct_change()                # Percentage change\n",
    "df.rolling(window=5).mean()    # Moving average\n",
    "df.groupby('sector').mean()    # Group and aggregate\n",
    "pd.merge(df1, df2, on='key')   # Merge DataFrames\n",
    "\n",
    "# Statistics\n",
    "df.describe()           # Summary statistics\n",
    "df.mean()              # Column means\n",
    "df.corr()              # Correlation matrix\n",
    "```\n",
    "\n",
    "### Financial Calculations:\n",
    "```python\n",
    "# Returns\n",
    "returns = prices.pct_change()\n",
    "cum_returns = (1 + returns).cumprod() - 1\n",
    "\n",
    "# Volatility (annualized)\n",
    "volatility = returns.std() * np.sqrt(252)\n",
    "\n",
    "# Sharpe Ratio\n",
    "sharpe = (annual_return - risk_free) / volatility\n",
    "\n",
    "# Moving averages\n",
    "ma = prices.rolling(window=20).mean()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Testing and Submission\n",
    "\n",
    "**Before moving on:**\n",
    "1. Complete all exercises using the sample data\n",
    "2. Verify your calculations make sense\n",
    "3. Export results to CSV where requested\n",
    "4. Understand the difference between NumPy and Pandas\n",
    "5. Know when to use each library\n",
    "6. Have your instructor manually check your work\n",
    "\n",
    "**Excellent work completing Lab 8!** ðŸŽ‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
